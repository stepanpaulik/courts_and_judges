setwd("~/Library/CloudStorage/OneDrive-Humboldt-UniversitaetzuBerlin,CMS/PhD/Courts and Judges/courts_and_judges/introduction_to_R")
knitr::opts_chunk$set(eval = FALSE)
# install.packages("tidyverse")
library(tidyverse)
judges = readRDS("../data/US_judges.rds")
knitr::opts_chunk$set(eval = FALSE)
metadata = readRDS("../data/US_metadata.rds")
dissents <- readRDS("~/Library/CloudStorage/OneDrive-Humboldt-UniversitaetzuBerlin,CMS/Programming/data/US_dissents.rds")
View(dissents)
View(metadata)
data = readRDS(url("https://github.com/stepanpaulik/courts_and_judges/raw/main/data/rand_forest_exercise.rds")) %>%
drop_na() %>%
mutate(successful = as.character(successful)) %>%
mutate(across(where(is.character), as.factor))
View(data)
save.image(file = "workshop_data.RData")
mod = rand_forest(mtry = 10,
trees = 1000, # This is not a hyperparameter but you can play around a little bit too and see how it impacts the results
min_n = 3) %>%
set_mode("classification") %>%
set_engine("ranger")
xfun:pkg_attach2("kernlab", "tidymodels", "tidyverse", "skimr", "ranger", "xgboost", "word2vec", "parallel", "udpipe", "quanteda", "seededlda", "quanteda.textstats", "tidytext")
install.packages("xfun")
install.packages("xfun")
install.packages("xfun")
xfun:pkg_attach2("kernlab", "tidymodels", "tidyverse", "skimr", "ranger", "xgboost", "word2vec", "parallel", "udpipe", "quanteda", "seededlda", "quanteda.textstats", "tidytext")
xfun:pkg_attach2("kernlab", "tidymodels", "tidyverse", "skimr", "ranger", "xgboost", "word2vec", "parallel", "udpipe", "quanteda", "seededlda", "quanteda.textstats", "tidytext")
xfun::pkg_attach2("kernlab", "tidymodels", "tidyverse", "skimr", "ranger", "xgboost", "word2vec", "parallel", "udpipe", "quanteda", "seededlda", "quanteda.textstats", "tidytext")
save.image(file = "workshop_data.RData")
wflow = workflow() %>%
add_recipe(rec) %>%
add_model(mod)
mod = rand_forest(mtry = 10,
trees = 1000, # This is not a hyperparameter but you can play around a little bit too and see how it impacts the results
min_n = 3) %>%
set_mode("classification") %>%
set_engine("ranger")
load(file = "workshop_data.RData")
install.packages("xfun")
xfun::pkg_attach2("kernlab", "tidymodels", "tidyverse", "skimr", "ranger", "xgboost", "word2vec", "parallel", "udpipe", "quanteda", "seededlda", "quanteda.textstats", "tidytext")
load(file = "workshop_data.RData")
install.packages("xfun")
NSS_df = readRDS(url("https://github.com/stepanpaulik/courts_and_judges/raw/main/data/NSS_df.rds"))
# Check the ability distribution
NSS_df %>%
ggplot() +
geom_density(aes(x = ability, group = phd, color = phd))
View(NSS_df)
NSS_df = NSS_df %>% select(-phd)
View(NSS_df)
save.image(file = "workshop_data.RData")
# Load data dynamically from a github page (should've done this earlier)
load(url("https://github.com/jfjelstul/law-and-courts-workshop/raw/master/data/text_corpus.RData")) %>% as_tibble()
View(text_corpus)
View(text_corpus)
save.image(file = "workshop_data.RData")
network_analysis = text_corpus %>%
select(ecli, text) %>%
filter(section == "grounds")
network_analysis = text_corpus %>%
filter(section == "grounds") %>%
select(ecli, text)
load(url("https://github.com/stepanpaulik/courts_and_judges/raw/main/introduction_to_R/workshop_data.RData"))
